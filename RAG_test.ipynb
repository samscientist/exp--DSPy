{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f133c37",
   "metadata": {},
   "source": [
    "Install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-28T14:26:13.490283Z",
     "start_time": "2024-05-28T14:26:13.411182Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U -r requirements.txt\n",
    "# The options `-q`, `-U`, `-r` respectively refers to 'quiet', 'upgrade', 'requirement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46f946bf274bc79",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset  # HuggingFace dataset loading function\n",
    "\n",
    "dataset = load_dataset(\"allganize/RAG-Evaluation-Dataset-KO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f9b4e",
   "metadata": {},
   "source": [
    "View the dataset how it is composed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bf8e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['domain', 'question', 'target_answer', 'target_file_name', 'target_page_no', 'context_type', 'alli_gpt-4-turbo_answer', 'alli_gpt-4-turbo_is_correct', 'alli_gpt-4_answer', 'alli_gpt-4_is_correct', 'alli_claude3-opus_answer', 'alli_claude3-opus_is_correct', 'alli_eeve_answer', 'alli_eeve_is_correct', 'alli_llama3_answer', 'alli_llama3_is_correct', 'langchain_gpt-4-turbo_answer', 'langchain_gpt-4-turbo_is_correct', 'langchain_gpt-3.5-turbo_answer', 'langchain_gpt-3.5-turbo_is_correct', 'openai_assistant_gpt-4-turbo_answer', 'openai_assistant_gpt-4-turbo_is_correct', 'openai_assistant_gpt-4_answer', 'openai_assistant_gpt-4_is_correct', 'cohere_command-r_answer', 'cohere_command-r_is_correct', 'cohere_command-r-plus_answer', 'cohere_command-r-plus_is_correct', 'anything_llm_gpt-4-turbo_answer', 'anything_llm_gpt-4-turbo_is_correct', 'anything_llm_gpt-3.5-turbo_answer', 'anything_llm_gpt-3.5-turbo_is_correct', 'anything_llm_claude3-opus_answer', 'anything_llm_claude3-opus_is_correct'],\n",
       "        num_rows: 300\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8905beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = dataset['test'].to_pandas()\n",
    "documents = df_pandas['target_answer'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "055e16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(range(1,len(documents)+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Before the steps below, Qdrant must be running in the background.\n",
    "</br>This could be acheived by executing the following shell command.[^1]\n",
    "\n",
    "```shell\n",
    "docker run -p 6333:6333 -p 6334:6334 \\\n",
    "   -v $(pwd)/qdrant_storage:/qdrant/storage:z \\\n",
    "   qdrant/qdrant\n",
    "```\n",
    "\n",
    "[^1]: https://qdrant.tech/documentation/quick-start/#download-and-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8381300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "client = QdrantClient(\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc7fe9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.delete_collection(collection_name= \"general_finance_service\")\n",
    "client.add(collection_name= \"general_finance_service\",\n",
    "           documents= documents,\n",
    "           ids= ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94153e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "\n",
    "load_dotenv()  # load the `.env` file\n",
    "\n",
    "# Configure language model\n",
    "llm = dspy.Google(\n",
    "    api_key=environ.get('API_KEY')  # Gemini API Key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b19f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.retrieve.qdrant_rm import QdrantRM\n",
    "\n",
    "qdrant_retriever_model = QdrantRM(\"general_finance_service\", client, k=10)\n",
    "\n",
    "dspy.settings.configure(lm=llm, rm=qdrant_retriever_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.set_model(\"intfloat/multilingual-e5-large\") # not tested yet\n",
    "# ※ https://qdrant.github.io/fastembed/examples/Supported_Models/#supported-text-embedding-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c64b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3908f29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2010, 5% of colon cancer and 9% of rectal cancer in the United States occurred in people under 50 years of age. According to recent trends, these percentages are expected to increase to 11% of all colon cancer patients and 22% of rectal cancer patients by 2030.\n"
     ]
    }
   ],
   "source": [
    "uncompiled_rag = RAG()\n",
    "\n",
    "query = \"2010년 미국에서 50세 미만에서 발생한 직장암과 결장암의 퍼센트는 어떻게 되며, 이 비율이 2030년에는 어떻게 변할 것으로 예상되는가?\"\n",
    "\n",
    "response = uncompiled_rag(query)\n",
    "\n",
    "print(response.answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
